---------------
dataset folder
---------------
CTR_30.zip
: It contains 30 text files, each of which was extracted from a webpage about Hurricane Isaac disaster.  This is a homogeneous dataset.

NYT_1000_IDs_EXP3.txt
: It contains 1000 document IDs of the New York Times articles used in this study.  Considering that the NYT corpus is a proprietary, we provide only the IDs, and not the actual text content.

NYT_1000_taggedTopics_EXP3.sql
: This is a database table dump, which contains various topics extracted from the NYT_1000 dataset using diverse Xpantrac settings with 3 different search APIs, as well as the baseline, TF*IDF, and OpenCalais. 

RelevanceRatingBy3HumanRaters_EXP2_CTR_and_VARIOUS_30(xpantrac,tfidf topics).xlsx
: This file contains ratings for each topic, which was extracted by using Xpantrac as well as a baseline, TF*IDF, from both CTR_30 and VARIOUS_30 data sets.  The 5-point Likert scale was used for the relevance rating by three human raters.

TagsBy3HumanIndexers_EXP1_CTR_30.txt
: It contains topic tags, indexed by 3 humans, for each of 30 documents in the CTR_30 dataset.

TagsBy5HumanIndexers_EXP1_VARIOUS_30.txt
: It contains topic tags, indexed by 5 humans, for each of 30 documents in the VARIOUS_30 dataset.

VARIOUS_30.zip
: It contains 30 text files about diverse content including natural and man-made disasters, health issues, civil conflicts, and epidemics. This is a heterogeneous dataset.

---------------
code folder
---------------
custom_stops.txt
: It contains additional stopwords.

pos_tagger.py
: This script contains part-of-speech taggers that are chained as the backoff taggers of each other, in order to improve the tagging accuracy.

stopwords.txt
: It contains a list of general purpose stopwords.

Xpantrac_bing_buildCache.py
: This script expands provided input texts using a commercial search engine API (e.g., Bing API), then stores the expanded textual information in a database table for later analysis and topic extraction.

Xpantrac_bing_DB.py
: This script extracts the expanded textual information from a database table, which had been stored using Xpantrac_bing_buildCache.py.  One of the benefits is to extract topics for each varying parameter setting, for example, different values of the "number of API return" parameter.

Xpantrac_extractTopics_bing.py
: This script is an autonomous topic extraction script to identify topic tags given textual documents.  The Bing Azure API was used in this script.

---------------
script folder
---------------
compute_IIC_human_machine.py
: It computes the Rolling's Inter-Indexer Consistency (IIC) between topic groups, which were identified by human indexers and by Xpantrac.

compute_IIC_human_opencalais.py
: It computes the Rolling's Inter-Indexer Consistency (IIC) between topic groups, which were identified by human indexers and by OpenCalais NLP API.

custom_stops.txt
: It contains additional stopwords.

stopwords.txt
: It contains a list of general purpose stopwords.

topic_extraction_opencalais.py
: This script extracts topics using the OpenCalais NLP API.

topic_extraction_TFIDF_CTR30,VARIOUS_30.py
: It extracts topics by using the baseline, TF*IDF, from both CTR_30 and VARIOUS_30 datasets.

topic_extraction_TFIDF_NYT_1000.py
: It extracts topic tags by using the baseline, TF*IDF, from the NYT_1000 dataset.

topic_tag_evaluator.py
: This script computes the metrics such as precision, recall, and F1 of topics generated by Xpantrac with various settings and used search APIs, for the NYT_1000 dataset.

---------------
survey folder
---------------
DemographicsQuestionnaire_EXP1.docx
: a demographic survey form used for the Experiment 1.

DemographicsQuestionnaire_EXP4.pdf
: a demographic survey form used for the Experiment 4.

ExitQuestionnaire_EXP4.pdf
: It asks for mostly the usefulness and satisfaction of the Xpantrac User Interface.

TaskQuestionnaire_EXP1_CTR30.docx
: It is a data collection tool, and three human indexers assigned topic tags for each document in CTR_30.

TaskQuestionnaire_EXP2_CTR30.pdf
: Users assigned the topic relevance rating using this questionnaire for the CTR_30 dataset.

TaskQuestionnaire_EXP2_VARIOUS_30.pdf
: Users assigned the topic relevance rating using this questionnaire for the VARIOUS_30 dataset. 

TaskQuestionnaire_EXP4_TYPE1.docx
: It includes instructions to use the Xpantrac UI, an exercise task, and three main tasks. Different questionnaire types contain different set of the documents selected from the CTR_30, VARIOUS_30, and NYT_1000 datasets.

TaskQuestionnaire_EXP4_TYPE2.docx
: Same as the description above.

TaskQuestionnaire_EXP4_TYPE3.docx
: Same as the description above.

TaskQuestionnaire_EXP4_TYPE4.docx
: Same as the description above.

TaskQuestionnaire_EXP4_TYPE5.docx
: Same as the description above.

TaskQuestionnaire_EXP4_TYPE6.docx
: Same as the description above.

TaskQuestionnaire_EXP4_TYPE7.docx
: Same as the description above.

XpantracTutorial.pdf
: This is a tutorial for using Xpantrac.  It was developed for conducting the Experiment 4 (usability study).
